{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1oWgoSlBUsSiAoALR35MAUEKsDlZAGYpi","authorship_tag":"ABX9TyO81VL43cFQTACsLrhbOTAf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import torchtext\n","from torchtext import data, datasets\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","import spacy\n","import numpy as np\n","\n","import random\n","import math\n","import time\n","import torch.nn.functional as F"],"metadata":{"id":"8Ll1TdFg_O5s","executionInfo":{"status":"ok","timestamp":1719649933295,"user_tz":-180,"elapsed":10143,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["! pip install -U torchtext==0.6.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"1zYGRW0FBphh","executionInfo":{"status":"ok","timestamp":1719649901171,"user_tz":-180,"elapsed":87245,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"c832c8b3-c08b-40f0-dd22-9084c68a107e","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.6.0\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.3.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.25.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2024.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.15.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->torchtext==0.6.0)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torchtext==0.6.0)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.18.0\n","    Uninstalling torchtext-0.18.0:\n","      Successfully uninstalled torchtext-0.18.0\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torchtext-0.6.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torchtext"]},"id":"cf1b5a91e5804211b309c7f0e5da2a6b"}},"metadata":{}}]},{"cell_type":"code","source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"rsqs1s1DBdou","executionInfo":{"status":"ok","timestamp":1719659449225,"user_tz":-180,"elapsed":257,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":267,"outputs":[]},{"cell_type":"code","source":["from spacy.lang.ru import Russian"],"metadata":{"id":"XSv3u5XuITl8","executionInfo":{"status":"ok","timestamp":1719659450231,"user_tz":-180,"elapsed":2,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":268,"outputs":[]},{"cell_type":"code","source":["spacy_ru = Russian()\n","spacy_en = spacy.load('en_core_web_sm')"],"metadata":{"id":"9lIHrPm-BhYg","executionInfo":{"status":"ok","timestamp":1719659452456,"user_tz":-180,"elapsed":1134,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":269,"outputs":[]},{"cell_type":"code","source":["def tokenize_ru(text):\n","\n","    return [tok.text for tok in spacy_ru.tokenizer(text)]\n","\n","def tokenize_en(text):\n","\n","    return [tok.text for tok in spacy_en.tokenizer(text)]"],"metadata":{"id":"25WMHj82BjPS","executionInfo":{"status":"ok","timestamp":1719659452456,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":270,"outputs":[]},{"cell_type":"code","source":["SRC = data.Field(tokenize = tokenize_ru,\n","            init_token = '<sos>',\n","            eos_token = '<eos>',\n","            lower = True,\n","            include_lengths = True)\n","\n","TRG = data.Field(tokenize = tokenize_en,\n","            init_token = '<sos>',\n","            eos_token = '<eos>',\n","            lower = True)"],"metadata":{"id":"V6mgBRG7BmBS","executionInfo":{"status":"ok","timestamp":1719661422119,"user_tz":-180,"elapsed":279,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":320,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"id":"H1i8a0S8TQAa","executionInfo":{"status":"ok","timestamp":1719661422606,"user_tz":-180,"elapsed":2,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc839919-93c4-4c2a-a00e-90ab45da45ce"},"execution_count":321,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"code","source":["fields = [('src', SRC), ('trg', TRG)]"],"metadata":{"id":"zQ_HXsmWCBBD","executionInfo":{"status":"ok","timestamp":1719661423554,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":322,"outputs":[]},{"cell_type":"code","source":["nmt_data = data.TabularDataset(path=\"/content/drive/MyDrive/31/Rus-Eng-small-cleaned-short.tsv\", format='tsv', fields=fields)"],"metadata":{"id":"K-wv6egBCIYj","executionInfo":{"status":"ok","timestamp":1719661424659,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":323,"outputs":[]},{"cell_type":"code","source":["train_data, valid_data, test_data = nmt_data.split(split_ratio=[0.8, 0.15, 0.05], random_state=random.seed(SEED))"],"metadata":{"id":"Oin8PlmbC32S","executionInfo":{"status":"ok","timestamp":1719661424973,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":324,"outputs":[]},{"cell_type":"code","source":["print(f\"Number of training examples: {len(train_data.examples)}\")\n","print(f\"Number of validation examples: {len(valid_data.examples)}\")\n","print(f\"Number of testing examples: {len(test_data.examples)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8GzKpIqDaOr","executionInfo":{"status":"ok","timestamp":1719661425339,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"71db345e-073d-4c52-ca30-d737fe8504c7"},"execution_count":325,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training examples: 79\n","Number of validation examples: 5\n","Number of testing examples: 15\n"]}]},{"cell_type":"code","source":["print(vars(train_data.examples[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QpxIlJ2CElcQ","executionInfo":{"status":"ok","timestamp":1719661425959,"user_tz":-180,"elapsed":2,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"b35440e5-b286-46b7-893b-a9594bf6d0c7"},"execution_count":326,"outputs":[{"output_type":"stream","name":"stdout","text":["{'src': ['это', 'мой', 'ответ', '!'], 'trg': ['that', \"'s\", 'my', 'line', '!']}\n"]}]},{"cell_type":"code","source":["SRC.build_vocab(train_data, min_freq = 2)\n","TRG.build_vocab(train_data, min_freq = 2)"],"metadata":{"id":"y93xR9SjEAqm","executionInfo":{"status":"ok","timestamp":1719661426350,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":327,"outputs":[]},{"cell_type":"code","source":["print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n","print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"483-q3GbEDEj","executionInfo":{"status":"ok","timestamp":1719661430497,"user_tz":-180,"elapsed":259,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"9255d1aa-d0c6-4347-b19a-94bbb2a71aef"},"execution_count":328,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique tokens in source (de) vocabulary: 78\n","Unique tokens in target (en) vocabulary: 92\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 16\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","     batch_size = BATCH_SIZE,\n","     sort_within_batch = True,\n","     sort_key = lambda x : len(x.src),\n","     device = device)"],"metadata":{"id":"3dzAe7pJUk18","executionInfo":{"status":"ok","timestamp":1719661436833,"user_tz":-180,"elapsed":269,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":330,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","\n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n","\n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src, src_len):\n","\n","        embedded = self.dropout(self.embedding(src))\n","\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'))\n","\n","        packed_outputs, hidden = self.rnn(packed_embedded)\n","\n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n","\n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n","\n","        return outputs, hidden"],"metadata":{"id":"cfCSDGL6OyCC","executionInfo":{"status":"ok","timestamp":1719661438883,"user_tz":-180,"elapsed":277,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":331,"outputs":[]},{"cell_type":"code","source":["class Attention(nn.Module):\n","    def __init__(self, enc_hid_dim, dec_hid_dim):\n","        super().__init__()\n","\n","        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n","        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n","\n","    def forward(self, hidden, encoder_outputs, mask):\n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","\n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))\n","\n","        attention = self.v(energy).squeeze(2)\n","\n","        attention = attention.masked_fill(mask == 0, -1e10)\n","\n","        return F.softmax(attention, dim = 1)"],"metadata":{"id":"Thiax6F8SzOH","executionInfo":{"status":"ok","timestamp":1719661441211,"user_tz":-180,"elapsed":296,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":332,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n","        super().__init__()\n","\n","        self.output_dim = output_dim\n","        self.attention = attention\n","\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","\n","        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n","\n","        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input, hidden, encoder_outputs, mask):\n","        input = input.unsqueeze(0)\n","\n","        embedded = self.dropout(self.embedding(input))\n","\n","        a = self.attention(hidden, encoder_outputs, mask)\n","\n","        a = a.unsqueeze(1)\n","\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","\n","        weighted = torch.bmm(a, encoder_outputs)\n","\n","        weighted = weighted.permute(1, 0, 2)\n","\n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","\n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n","\n","        assert (output == hidden).all()\n","\n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","\n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n","\n","        return prediction, hidden.squeeze(0), a.squeeze(1)"],"metadata":{"id":"RtC6acVrTAIu","executionInfo":{"status":"ok","timestamp":1719661442153,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":333,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, src_pad_idx, device):\n","        super().__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_pad_idx = src_pad_idx\n","        self.device = device\n","\n","    def create_mask(self, src):\n","        mask = (src != self.src_pad_idx).permute(1, 0)\n","        return mask\n","\n","    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n","\n","        batch_size = src.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","\n","        encoder_outputs, hidden = self.encoder(src, src_len)\n","\n","        input = trg[0,:]\n","\n","        mask = self.create_mask(src)\n","\n","\n","        for t in range(1, trg_len):\n","            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n","\n","            outputs[t] = output\n","\n","            teacher_force = random.random() < teacher_forcing_ratio\n","\n","            top1 = output.argmax(1)\n","\n","            input = trg[t] if teacher_force else top1\n","\n","        return outputs"],"metadata":{"id":"kZu4QB_6TDPr","executionInfo":{"status":"ok","timestamp":1719661443635,"user_tz":-180,"elapsed":2,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":334,"outputs":[]},{"cell_type":"code","source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 128\n","DEC_EMB_DIM = 128\n","ENC_HID_DIM = 128\n","DEC_HID_DIM = 128\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","\n","model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)"],"metadata":{"id":"l8hux43KTFGv","executionInfo":{"status":"ok","timestamp":1719661520457,"user_tz":-180,"elapsed":283,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":349,"outputs":[]},{"cell_type":"code","source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","\n","model.apply(init_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WIc-gY09TH1k","executionInfo":{"status":"ok","timestamp":1719661520849,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"0640f457-3e42-48f6-ebec-83a40aa84b8a"},"execution_count":350,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(78, 128)\n","    (rnn): GRU(128, 128, bidirectional=True)\n","    (fc): Linear(in_features=256, out_features=128, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (attention): Attention(\n","      (attn): Linear(in_features=384, out_features=128, bias=True)\n","      (v): Linear(in_features=128, out_features=1, bias=False)\n","    )\n","    (embedding): Embedding(92, 128)\n","    (rnn): GRU(384, 128)\n","    (fc_out): Linear(in_features=512, out_features=92, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{},"execution_count":350}]},{"cell_type":"code","source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJMIaabnTYAF","executionInfo":{"status":"ok","timestamp":1719661521795,"user_tz":-180,"elapsed":2,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"965295ee-3ee7-436a-d5ff-c65fd1c0d793"},"execution_count":351,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 546,780 trainable parameters\n"]}]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters())"],"metadata":{"id":"PNpF-1dGTao_","executionInfo":{"status":"ok","timestamp":1719661522766,"user_tz":-180,"elapsed":2,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":352,"outputs":[]},{"cell_type":"code","source":["TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"metadata":{"id":"wpMZTClDTb0v","executionInfo":{"status":"ok","timestamp":1719661523172,"user_tz":-180,"elapsed":2,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":353,"outputs":[]},{"cell_type":"code","source":["def train(model, iterator, optimizer, criterion, clip):\n","\n","    model.train()\n","\n","    epoch_loss = 0\n","\n","    for i, batch in enumerate(iterator):\n","\n","        src, src_len = batch.src\n","        trg = batch.trg\n","\n","        optimizer.zero_grad()\n","\n","        output = model(src, src_len, trg)\n","\n","        output_dim = output.shape[-1]\n","\n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","\n","        loss = criterion(output, trg)\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"],"metadata":{"id":"wRYSsThFTdNR","executionInfo":{"status":"ok","timestamp":1719661524345,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":354,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, iterator, criterion):\n","\n","    model.eval()\n","\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","\n","        for i, batch in enumerate(iterator):\n","\n","            src, src_len = batch.src\n","            trg = batch.trg\n","\n","            output = model(src, src_len, trg, 0) #turn off teacher forcing\n","\n","            output_dim = output.shape[-1]\n","\n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"],"metadata":{"id":"juc0v5yZTfcl","executionInfo":{"status":"ok","timestamp":1719661525245,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":355,"outputs":[]},{"cell_type":"code","source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"BHV5iTEuThNc","executionInfo":{"status":"ok","timestamp":1719661526445,"user_tz":-180,"elapsed":2,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":356,"outputs":[]},{"cell_type":"code","source":["from tensorboardX import SummaryWriter\n","import datetime\n","\n","#  Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"apMqjsukao8Y","executionInfo":{"status":"ok","timestamp":1719661527359,"user_tz":-180,"elapsed":2,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"f4a27e21-4676-4e15-f0f5-42fa764f5024"},"execution_count":357,"outputs":[{"output_type":"stream","name":"stdout","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]}]},{"cell_type":"code","source":["!pip install tensorboardX"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4TWpnjxearSV","executionInfo":{"status":"ok","timestamp":1719660929466,"user_tz":-180,"elapsed":1696,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"03cb141d-9abb-4169-fc91-c29d3adc5996"},"execution_count":318,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["N_EPOCHS = 200\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","writer = SummaryWriter()\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut4-model.pt')\n","\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n","    writer.add_scalar(\"Train Loss\", train_loss, epoch+1)\n","    writer.add_scalar(\"Train PPL\", math.exp(train_loss), epoch+1)\n","    writer.add_scalar(\"Val. Loss\", valid_loss, epoch+1)\n","    writer.add_scalar(\"Val. PPL\", math.exp(valid_loss), epoch+1)\n","\n","writer.close()"],"metadata":{"id":"_lLE931rUxfr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719661765447,"user_tz":-180,"elapsed":130834,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"51846b25-e91a-41bc-822e-5b2e9add3847"},"execution_count":365,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Time: 0m 0s\n","\tTrain Loss: 1.460 | Train PPL:   4.304\n","\t Val. Loss: 1.956 |  Val. PPL:   7.072\n","Epoch: 02 | Time: 0m 0s\n","\tTrain Loss: 1.503 | Train PPL:   4.496\n","\t Val. Loss: 2.067 |  Val. PPL:   7.899\n","Epoch: 03 | Time: 0m 0s\n","\tTrain Loss: 1.376 | Train PPL:   3.958\n","\t Val. Loss: 2.171 |  Val. PPL:   8.769\n","Epoch: 04 | Time: 0m 1s\n","\tTrain Loss: 1.414 | Train PPL:   4.112\n","\t Val. Loss: 2.185 |  Val. PPL:   8.892\n","Epoch: 05 | Time: 0m 0s\n","\tTrain Loss: 1.565 | Train PPL:   4.781\n","\t Val. Loss: 1.993 |  Val. PPL:   7.334\n","Epoch: 06 | Time: 0m 0s\n","\tTrain Loss: 1.502 | Train PPL:   4.492\n","\t Val. Loss: 2.027 |  Val. PPL:   7.592\n","Epoch: 07 | Time: 0m 0s\n","\tTrain Loss: 1.395 | Train PPL:   4.035\n","\t Val. Loss: 2.042 |  Val. PPL:   7.706\n","Epoch: 08 | Time: 0m 0s\n","\tTrain Loss: 1.447 | Train PPL:   4.249\n","\t Val. Loss: 2.019 |  Val. PPL:   7.529\n","Epoch: 09 | Time: 0m 0s\n","\tTrain Loss: 1.337 | Train PPL:   3.809\n","\t Val. Loss: 1.964 |  Val. PPL:   7.125\n","Epoch: 10 | Time: 0m 0s\n","\tTrain Loss: 1.311 | Train PPL:   3.708\n","\t Val. Loss: 2.063 |  Val. PPL:   7.868\n","Epoch: 11 | Time: 0m 0s\n","\tTrain Loss: 1.232 | Train PPL:   3.429\n","\t Val. Loss: 2.073 |  Val. PPL:   7.952\n","Epoch: 12 | Time: 0m 0s\n","\tTrain Loss: 1.296 | Train PPL:   3.655\n","\t Val. Loss: 2.197 |  Val. PPL:   8.994\n","Epoch: 13 | Time: 0m 0s\n","\tTrain Loss: 1.148 | Train PPL:   3.151\n","\t Val. Loss: 2.167 |  Val. PPL:   8.733\n","Epoch: 14 | Time: 0m 0s\n","\tTrain Loss: 1.283 | Train PPL:   3.608\n","\t Val. Loss: 1.980 |  Val. PPL:   7.243\n","Epoch: 15 | Time: 0m 0s\n","\tTrain Loss: 1.352 | Train PPL:   3.864\n","\t Val. Loss: 2.071 |  Val. PPL:   7.930\n","Epoch: 16 | Time: 0m 0s\n","\tTrain Loss: 1.205 | Train PPL:   3.338\n","\t Val. Loss: 2.178 |  Val. PPL:   8.829\n","Epoch: 17 | Time: 0m 0s\n","\tTrain Loss: 1.132 | Train PPL:   3.102\n","\t Val. Loss: 1.965 |  Val. PPL:   7.134\n","Epoch: 18 | Time: 0m 0s\n","\tTrain Loss: 1.190 | Train PPL:   3.288\n","\t Val. Loss: 1.969 |  Val. PPL:   7.163\n","Epoch: 19 | Time: 0m 0s\n","\tTrain Loss: 1.168 | Train PPL:   3.215\n","\t Val. Loss: 1.467 |  Val. PPL:   4.335\n","Epoch: 20 | Time: 0m 0s\n","\tTrain Loss: 1.234 | Train PPL:   3.435\n","\t Val. Loss: 2.113 |  Val. PPL:   8.275\n","Epoch: 21 | Time: 0m 0s\n","\tTrain Loss: 1.221 | Train PPL:   3.390\n","\t Val. Loss: 2.055 |  Val. PPL:   7.810\n","Epoch: 22 | Time: 0m 0s\n","\tTrain Loss: 1.178 | Train PPL:   3.249\n","\t Val. Loss: 2.138 |  Val. PPL:   8.482\n","Epoch: 23 | Time: 0m 0s\n","\tTrain Loss: 1.248 | Train PPL:   3.484\n","\t Val. Loss: 1.511 |  Val. PPL:   4.533\n","Epoch: 24 | Time: 0m 0s\n","\tTrain Loss: 0.984 | Train PPL:   2.674\n","\t Val. Loss: 2.151 |  Val. PPL:   8.593\n","Epoch: 25 | Time: 0m 0s\n","\tTrain Loss: 1.101 | Train PPL:   3.007\n","\t Val. Loss: 2.173 |  Val. PPL:   8.786\n","Epoch: 26 | Time: 0m 0s\n","\tTrain Loss: 1.157 | Train PPL:   3.180\n","\t Val. Loss: 1.664 |  Val. PPL:   5.282\n","Epoch: 27 | Time: 0m 0s\n","\tTrain Loss: 1.020 | Train PPL:   2.772\n","\t Val. Loss: 1.388 |  Val. PPL:   4.006\n","Epoch: 28 | Time: 0m 0s\n","\tTrain Loss: 1.126 | Train PPL:   3.085\n","\t Val. Loss: 2.082 |  Val. PPL:   8.021\n","Epoch: 29 | Time: 0m 0s\n","\tTrain Loss: 1.032 | Train PPL:   2.808\n","\t Val. Loss: 2.159 |  Val. PPL:   8.665\n","Epoch: 30 | Time: 0m 0s\n","\tTrain Loss: 1.081 | Train PPL:   2.947\n","\t Val. Loss: 2.323 |  Val. PPL:  10.209\n","Epoch: 31 | Time: 0m 0s\n","\tTrain Loss: 1.036 | Train PPL:   2.819\n","\t Val. Loss: 2.095 |  Val. PPL:   8.127\n","Epoch: 32 | Time: 0m 0s\n","\tTrain Loss: 1.051 | Train PPL:   2.860\n","\t Val. Loss: 2.170 |  Val. PPL:   8.762\n","Epoch: 33 | Time: 0m 0s\n","\tTrain Loss: 1.066 | Train PPL:   2.903\n","\t Val. Loss: 2.302 |  Val. PPL:   9.994\n","Epoch: 34 | Time: 0m 0s\n","\tTrain Loss: 1.026 | Train PPL:   2.789\n","\t Val. Loss: 2.378 |  Val. PPL:  10.783\n","Epoch: 35 | Time: 0m 0s\n","\tTrain Loss: 1.040 | Train PPL:   2.828\n","\t Val. Loss: 1.950 |  Val. PPL:   7.029\n","Epoch: 36 | Time: 0m 0s\n","\tTrain Loss: 0.956 | Train PPL:   2.601\n","\t Val. Loss: 2.227 |  Val. PPL:   9.269\n","Epoch: 37 | Time: 0m 0s\n","\tTrain Loss: 0.997 | Train PPL:   2.709\n","\t Val. Loss: 1.753 |  Val. PPL:   5.773\n","Epoch: 38 | Time: 0m 0s\n","\tTrain Loss: 1.132 | Train PPL:   3.101\n","\t Val. Loss: 2.150 |  Val. PPL:   8.584\n","Epoch: 39 | Time: 0m 0s\n","\tTrain Loss: 0.982 | Train PPL:   2.670\n","\t Val. Loss: 2.185 |  Val. PPL:   8.895\n","Epoch: 40 | Time: 0m 0s\n","\tTrain Loss: 0.969 | Train PPL:   2.636\n","\t Val. Loss: 2.246 |  Val. PPL:   9.453\n","Epoch: 41 | Time: 0m 0s\n","\tTrain Loss: 1.007 | Train PPL:   2.737\n","\t Val. Loss: 2.259 |  Val. PPL:   9.570\n","Epoch: 42 | Time: 0m 0s\n","\tTrain Loss: 0.897 | Train PPL:   2.452\n","\t Val. Loss: 2.460 |  Val. PPL:  11.708\n","Epoch: 43 | Time: 0m 0s\n","\tTrain Loss: 0.994 | Train PPL:   2.703\n","\t Val. Loss: 1.476 |  Val. PPL:   4.376\n","Epoch: 44 | Time: 0m 0s\n","\tTrain Loss: 0.887 | Train PPL:   2.428\n","\t Val. Loss: 1.415 |  Val. PPL:   4.118\n","Epoch: 45 | Time: 0m 0s\n","\tTrain Loss: 0.832 | Train PPL:   2.298\n","\t Val. Loss: 1.517 |  Val. PPL:   4.559\n","Epoch: 46 | Time: 0m 0s\n","\tTrain Loss: 0.931 | Train PPL:   2.536\n","\t Val. Loss: 1.352 |  Val. PPL:   3.866\n","Epoch: 47 | Time: 0m 0s\n","\tTrain Loss: 0.934 | Train PPL:   2.545\n","\t Val. Loss: 1.540 |  Val. PPL:   4.665\n","Epoch: 48 | Time: 0m 0s\n","\tTrain Loss: 0.905 | Train PPL:   2.472\n","\t Val. Loss: 1.452 |  Val. PPL:   4.273\n","Epoch: 49 | Time: 0m 0s\n","\tTrain Loss: 0.830 | Train PPL:   2.294\n","\t Val. Loss: 1.304 |  Val. PPL:   3.684\n","Epoch: 50 | Time: 0m 0s\n","\tTrain Loss: 0.863 | Train PPL:   2.370\n","\t Val. Loss: 1.416 |  Val. PPL:   4.120\n","Epoch: 51 | Time: 0m 0s\n","\tTrain Loss: 0.852 | Train PPL:   2.345\n","\t Val. Loss: 1.474 |  Val. PPL:   4.368\n","Epoch: 52 | Time: 0m 0s\n","\tTrain Loss: 0.863 | Train PPL:   2.370\n","\t Val. Loss: 1.393 |  Val. PPL:   4.026\n","Epoch: 53 | Time: 0m 0s\n","\tTrain Loss: 0.803 | Train PPL:   2.233\n","\t Val. Loss: 2.270 |  Val. PPL:   9.678\n","Epoch: 54 | Time: 0m 0s\n","\tTrain Loss: 0.827 | Train PPL:   2.286\n","\t Val. Loss: 1.520 |  Val. PPL:   4.573\n","Epoch: 55 | Time: 0m 0s\n","\tTrain Loss: 0.807 | Train PPL:   2.241\n","\t Val. Loss: 1.568 |  Val. PPL:   4.798\n","Epoch: 56 | Time: 0m 0s\n","\tTrain Loss: 0.777 | Train PPL:   2.175\n","\t Val. Loss: 1.505 |  Val. PPL:   4.503\n","Epoch: 57 | Time: 0m 0s\n","\tTrain Loss: 0.783 | Train PPL:   2.187\n","\t Val. Loss: 2.368 |  Val. PPL:  10.680\n","Epoch: 58 | Time: 0m 0s\n","\tTrain Loss: 0.763 | Train PPL:   2.145\n","\t Val. Loss: 1.590 |  Val. PPL:   4.906\n","Epoch: 59 | Time: 0m 0s\n","\tTrain Loss: 0.776 | Train PPL:   2.174\n","\t Val. Loss: 1.529 |  Val. PPL:   4.612\n","Epoch: 60 | Time: 0m 0s\n","\tTrain Loss: 0.731 | Train PPL:   2.077\n","\t Val. Loss: 1.601 |  Val. PPL:   4.956\n","Epoch: 61 | Time: 0m 0s\n","\tTrain Loss: 0.737 | Train PPL:   2.089\n","\t Val. Loss: 1.707 |  Val. PPL:   5.513\n","Epoch: 62 | Time: 0m 0s\n","\tTrain Loss: 0.734 | Train PPL:   2.083\n","\t Val. Loss: 2.202 |  Val. PPL:   9.040\n","Epoch: 63 | Time: 0m 0s\n","\tTrain Loss: 0.733 | Train PPL:   2.080\n","\t Val. Loss: 1.240 |  Val. PPL:   3.457\n","Epoch: 64 | Time: 0m 0s\n","\tTrain Loss: 0.806 | Train PPL:   2.239\n","\t Val. Loss: 1.444 |  Val. PPL:   4.236\n","Epoch: 65 | Time: 0m 0s\n","\tTrain Loss: 0.717 | Train PPL:   2.048\n","\t Val. Loss: 1.316 |  Val. PPL:   3.727\n","Epoch: 66 | Time: 0m 0s\n","\tTrain Loss: 0.671 | Train PPL:   1.956\n","\t Val. Loss: 1.709 |  Val. PPL:   5.522\n","Epoch: 67 | Time: 0m 0s\n","\tTrain Loss: 0.702 | Train PPL:   2.018\n","\t Val. Loss: 2.332 |  Val. PPL:  10.297\n","Epoch: 68 | Time: 0m 0s\n","\tTrain Loss: 0.714 | Train PPL:   2.041\n","\t Val. Loss: 1.559 |  Val. PPL:   4.755\n","Epoch: 69 | Time: 0m 0s\n","\tTrain Loss: 0.646 | Train PPL:   1.907\n","\t Val. Loss: 1.478 |  Val. PPL:   4.385\n","Epoch: 70 | Time: 0m 0s\n","\tTrain Loss: 0.622 | Train PPL:   1.863\n","\t Val. Loss: 1.534 |  Val. PPL:   4.639\n","Epoch: 71 | Time: 0m 0s\n","\tTrain Loss: 0.741 | Train PPL:   2.097\n","\t Val. Loss: 1.482 |  Val. PPL:   4.401\n","Epoch: 72 | Time: 0m 0s\n","\tTrain Loss: 0.635 | Train PPL:   1.888\n","\t Val. Loss: 1.664 |  Val. PPL:   5.283\n","Epoch: 73 | Time: 0m 0s\n","\tTrain Loss: 0.689 | Train PPL:   1.991\n","\t Val. Loss: 1.542 |  Val. PPL:   4.676\n","Epoch: 74 | Time: 0m 0s\n","\tTrain Loss: 0.579 | Train PPL:   1.785\n","\t Val. Loss: 1.494 |  Val. PPL:   4.455\n","Epoch: 75 | Time: 0m 0s\n","\tTrain Loss: 0.621 | Train PPL:   1.860\n","\t Val. Loss: 1.572 |  Val. PPL:   4.815\n","Epoch: 76 | Time: 0m 0s\n","\tTrain Loss: 0.669 | Train PPL:   1.952\n","\t Val. Loss: 1.565 |  Val. PPL:   4.781\n","Epoch: 77 | Time: 0m 0s\n","\tTrain Loss: 0.556 | Train PPL:   1.743\n","\t Val. Loss: 1.578 |  Val. PPL:   4.847\n","Epoch: 78 | Time: 0m 0s\n","\tTrain Loss: 0.656 | Train PPL:   1.927\n","\t Val. Loss: 1.579 |  Val. PPL:   4.851\n","Epoch: 79 | Time: 0m 0s\n","\tTrain Loss: 0.639 | Train PPL:   1.894\n","\t Val. Loss: 1.676 |  Val. PPL:   5.345\n","Epoch: 80 | Time: 0m 0s\n","\tTrain Loss: 0.663 | Train PPL:   1.940\n","\t Val. Loss: 1.617 |  Val. PPL:   5.037\n","Epoch: 81 | Time: 0m 0s\n","\tTrain Loss: 0.619 | Train PPL:   1.857\n","\t Val. Loss: 1.559 |  Val. PPL:   4.756\n","Epoch: 82 | Time: 0m 0s\n","\tTrain Loss: 0.544 | Train PPL:   1.723\n","\t Val. Loss: 1.577 |  Val. PPL:   4.841\n","Epoch: 83 | Time: 0m 0s\n","\tTrain Loss: 0.502 | Train PPL:   1.653\n","\t Val. Loss: 1.567 |  Val. PPL:   4.791\n","Epoch: 84 | Time: 0m 0s\n","\tTrain Loss: 0.514 | Train PPL:   1.673\n","\t Val. Loss: 1.519 |  Val. PPL:   4.565\n","Epoch: 85 | Time: 0m 0s\n","\tTrain Loss: 0.553 | Train PPL:   1.738\n","\t Val. Loss: 1.611 |  Val. PPL:   5.008\n","Epoch: 86 | Time: 0m 0s\n","\tTrain Loss: 0.619 | Train PPL:   1.857\n","\t Val. Loss: 1.589 |  Val. PPL:   4.897\n","Epoch: 87 | Time: 0m 0s\n","\tTrain Loss: 0.568 | Train PPL:   1.764\n","\t Val. Loss: 1.527 |  Val. PPL:   4.603\n","Epoch: 88 | Time: 0m 0s\n","\tTrain Loss: 0.543 | Train PPL:   1.721\n","\t Val. Loss: 1.510 |  Val. PPL:   4.527\n","Epoch: 89 | Time: 0m 0s\n","\tTrain Loss: 0.621 | Train PPL:   1.861\n","\t Val. Loss: 1.567 |  Val. PPL:   4.791\n","Epoch: 90 | Time: 0m 0s\n","\tTrain Loss: 0.579 | Train PPL:   1.783\n","\t Val. Loss: 1.740 |  Val. PPL:   5.696\n","Epoch: 91 | Time: 0m 0s\n","\tTrain Loss: 0.518 | Train PPL:   1.679\n","\t Val. Loss: 1.561 |  Val. PPL:   4.765\n","Epoch: 92 | Time: 0m 0s\n","\tTrain Loss: 0.545 | Train PPL:   1.725\n","\t Val. Loss: 1.567 |  Val. PPL:   4.793\n","Epoch: 93 | Time: 0m 1s\n","\tTrain Loss: 0.515 | Train PPL:   1.673\n","\t Val. Loss: 1.621 |  Val. PPL:   5.057\n","Epoch: 94 | Time: 0m 1s\n","\tTrain Loss: 0.565 | Train PPL:   1.759\n","\t Val. Loss: 1.594 |  Val. PPL:   4.923\n","Epoch: 95 | Time: 0m 1s\n","\tTrain Loss: 0.442 | Train PPL:   1.556\n","\t Val. Loss: 1.588 |  Val. PPL:   4.896\n","Epoch: 96 | Time: 0m 0s\n","\tTrain Loss: 0.529 | Train PPL:   1.697\n","\t Val. Loss: 1.571 |  Val. PPL:   4.812\n","Epoch: 97 | Time: 0m 0s\n","\tTrain Loss: 0.534 | Train PPL:   1.706\n","\t Val. Loss: 1.533 |  Val. PPL:   4.632\n","Epoch: 98 | Time: 0m 0s\n","\tTrain Loss: 0.433 | Train PPL:   1.541\n","\t Val. Loss: 1.578 |  Val. PPL:   4.846\n","Epoch: 99 | Time: 0m 0s\n","\tTrain Loss: 0.507 | Train PPL:   1.660\n","\t Val. Loss: 1.586 |  Val. PPL:   4.886\n","Epoch: 100 | Time: 0m 0s\n","\tTrain Loss: 0.536 | Train PPL:   1.710\n","\t Val. Loss: 1.557 |  Val. PPL:   4.745\n","Epoch: 101 | Time: 0m 0s\n","\tTrain Loss: 0.481 | Train PPL:   1.618\n","\t Val. Loss: 1.598 |  Val. PPL:   4.941\n","Epoch: 102 | Time: 0m 0s\n","\tTrain Loss: 0.545 | Train PPL:   1.725\n","\t Val. Loss: 1.555 |  Val. PPL:   4.736\n","Epoch: 103 | Time: 0m 0s\n","\tTrain Loss: 0.528 | Train PPL:   1.695\n","\t Val. Loss: 1.467 |  Val. PPL:   4.338\n","Epoch: 104 | Time: 0m 0s\n","\tTrain Loss: 0.550 | Train PPL:   1.733\n","\t Val. Loss: 1.517 |  Val. PPL:   4.556\n","Epoch: 105 | Time: 0m 0s\n","\tTrain Loss: 0.454 | Train PPL:   1.574\n","\t Val. Loss: 1.537 |  Val. PPL:   4.652\n","Epoch: 106 | Time: 0m 0s\n","\tTrain Loss: 0.438 | Train PPL:   1.550\n","\t Val. Loss: 1.576 |  Val. PPL:   4.834\n","Epoch: 107 | Time: 0m 0s\n","\tTrain Loss: 0.400 | Train PPL:   1.492\n","\t Val. Loss: 1.598 |  Val. PPL:   4.945\n","Epoch: 108 | Time: 0m 0s\n","\tTrain Loss: 0.358 | Train PPL:   1.431\n","\t Val. Loss: 1.642 |  Val. PPL:   5.163\n","Epoch: 109 | Time: 0m 0s\n","\tTrain Loss: 0.388 | Train PPL:   1.475\n","\t Val. Loss: 1.612 |  Val. PPL:   5.013\n","Epoch: 110 | Time: 0m 0s\n","\tTrain Loss: 0.403 | Train PPL:   1.497\n","\t Val. Loss: 1.617 |  Val. PPL:   5.039\n","Epoch: 111 | Time: 0m 0s\n","\tTrain Loss: 0.441 | Train PPL:   1.555\n","\t Val. Loss: 1.640 |  Val. PPL:   5.156\n","Epoch: 112 | Time: 0m 0s\n","\tTrain Loss: 0.478 | Train PPL:   1.613\n","\t Val. Loss: 1.622 |  Val. PPL:   5.061\n","Epoch: 113 | Time: 0m 0s\n","\tTrain Loss: 0.464 | Train PPL:   1.591\n","\t Val. Loss: 1.606 |  Val. PPL:   4.981\n","Epoch: 114 | Time: 0m 1s\n","\tTrain Loss: 0.368 | Train PPL:   1.445\n","\t Val. Loss: 1.602 |  Val. PPL:   4.962\n","Epoch: 115 | Time: 0m 1s\n","\tTrain Loss: 0.464 | Train PPL:   1.590\n","\t Val. Loss: 1.611 |  Val. PPL:   5.010\n","Epoch: 116 | Time: 0m 1s\n","\tTrain Loss: 0.379 | Train PPL:   1.461\n","\t Val. Loss: 1.532 |  Val. PPL:   4.626\n","Epoch: 117 | Time: 0m 1s\n","\tTrain Loss: 0.462 | Train PPL:   1.587\n","\t Val. Loss: 1.553 |  Val. PPL:   4.726\n","Epoch: 118 | Time: 0m 0s\n","\tTrain Loss: 0.418 | Train PPL:   1.518\n","\t Val. Loss: 1.549 |  Val. PPL:   4.704\n","Epoch: 119 | Time: 0m 1s\n","\tTrain Loss: 0.410 | Train PPL:   1.506\n","\t Val. Loss: 1.638 |  Val. PPL:   5.145\n","Epoch: 120 | Time: 0m 0s\n","\tTrain Loss: 0.415 | Train PPL:   1.515\n","\t Val. Loss: 1.669 |  Val. PPL:   5.309\n","Epoch: 121 | Time: 0m 0s\n","\tTrain Loss: 0.395 | Train PPL:   1.484\n","\t Val. Loss: 1.587 |  Val. PPL:   4.888\n","Epoch: 122 | Time: 0m 0s\n","\tTrain Loss: 0.381 | Train PPL:   1.464\n","\t Val. Loss: 1.550 |  Val. PPL:   4.712\n","Epoch: 123 | Time: 0m 0s\n","\tTrain Loss: 0.355 | Train PPL:   1.426\n","\t Val. Loss: 1.606 |  Val. PPL:   4.983\n","Epoch: 124 | Time: 0m 0s\n","\tTrain Loss: 0.370 | Train PPL:   1.448\n","\t Val. Loss: 1.549 |  Val. PPL:   4.706\n","Epoch: 125 | Time: 0m 0s\n","\tTrain Loss: 0.342 | Train PPL:   1.408\n","\t Val. Loss: 1.625 |  Val. PPL:   5.077\n","Epoch: 126 | Time: 0m 0s\n","\tTrain Loss: 0.352 | Train PPL:   1.423\n","\t Val. Loss: 1.623 |  Val. PPL:   5.069\n","Epoch: 127 | Time: 0m 0s\n","\tTrain Loss: 0.330 | Train PPL:   1.391\n","\t Val. Loss: 1.666 |  Val. PPL:   5.292\n","Epoch: 128 | Time: 0m 0s\n","\tTrain Loss: 0.337 | Train PPL:   1.401\n","\t Val. Loss: 1.690 |  Val. PPL:   5.420\n","Epoch: 129 | Time: 0m 0s\n","\tTrain Loss: 0.365 | Train PPL:   1.440\n","\t Val. Loss: 1.684 |  Val. PPL:   5.389\n","Epoch: 130 | Time: 0m 0s\n","\tTrain Loss: 0.293 | Train PPL:   1.341\n","\t Val. Loss: 1.673 |  Val. PPL:   5.328\n","Epoch: 131 | Time: 0m 0s\n","\tTrain Loss: 0.313 | Train PPL:   1.367\n","\t Val. Loss: 1.655 |  Val. PPL:   5.232\n","Epoch: 132 | Time: 0m 0s\n","\tTrain Loss: 0.338 | Train PPL:   1.403\n","\t Val. Loss: 1.579 |  Val. PPL:   4.852\n","Epoch: 133 | Time: 0m 1s\n","\tTrain Loss: 0.358 | Train PPL:   1.431\n","\t Val. Loss: 1.626 |  Val. PPL:   5.083\n","Epoch: 134 | Time: 0m 1s\n","\tTrain Loss: 0.347 | Train PPL:   1.414\n","\t Val. Loss: 1.604 |  Val. PPL:   4.971\n","Epoch: 135 | Time: 0m 0s\n","\tTrain Loss: 0.322 | Train PPL:   1.380\n","\t Val. Loss: 1.686 |  Val. PPL:   5.397\n","Epoch: 136 | Time: 0m 0s\n","\tTrain Loss: 0.292 | Train PPL:   1.339\n","\t Val. Loss: 1.698 |  Val. PPL:   5.463\n","Epoch: 137 | Time: 0m 0s\n","\tTrain Loss: 0.336 | Train PPL:   1.399\n","\t Val. Loss: 1.658 |  Val. PPL:   5.250\n","Epoch: 138 | Time: 0m 0s\n","\tTrain Loss: 0.284 | Train PPL:   1.328\n","\t Val. Loss: 1.663 |  Val. PPL:   5.278\n","Epoch: 139 | Time: 0m 0s\n","\tTrain Loss: 0.309 | Train PPL:   1.362\n","\t Val. Loss: 1.662 |  Val. PPL:   5.270\n","Epoch: 140 | Time: 0m 0s\n","\tTrain Loss: 0.263 | Train PPL:   1.301\n","\t Val. Loss: 1.685 |  Val. PPL:   5.394\n","Epoch: 141 | Time: 0m 0s\n","\tTrain Loss: 0.273 | Train PPL:   1.314\n","\t Val. Loss: 1.704 |  Val. PPL:   5.496\n","Epoch: 142 | Time: 0m 0s\n","\tTrain Loss: 0.274 | Train PPL:   1.316\n","\t Val. Loss: 1.681 |  Val. PPL:   5.369\n","Epoch: 143 | Time: 0m 0s\n","\tTrain Loss: 0.245 | Train PPL:   1.278\n","\t Val. Loss: 1.659 |  Val. PPL:   5.256\n","Epoch: 144 | Time: 0m 0s\n","\tTrain Loss: 0.281 | Train PPL:   1.325\n","\t Val. Loss: 1.637 |  Val. PPL:   5.139\n","Epoch: 145 | Time: 0m 0s\n","\tTrain Loss: 0.323 | Train PPL:   1.382\n","\t Val. Loss: 1.691 |  Val. PPL:   5.426\n","Epoch: 146 | Time: 0m 1s\n","\tTrain Loss: 0.373 | Train PPL:   1.452\n","\t Val. Loss: 1.728 |  Val. PPL:   5.627\n","Epoch: 147 | Time: 0m 1s\n","\tTrain Loss: 0.264 | Train PPL:   1.302\n","\t Val. Loss: 1.709 |  Val. PPL:   5.521\n","Epoch: 148 | Time: 0m 1s\n","\tTrain Loss: 0.282 | Train PPL:   1.326\n","\t Val. Loss: 1.625 |  Val. PPL:   5.080\n","Epoch: 149 | Time: 0m 0s\n","\tTrain Loss: 0.321 | Train PPL:   1.378\n","\t Val. Loss: 1.649 |  Val. PPL:   5.204\n","Epoch: 150 | Time: 0m 0s\n","\tTrain Loss: 0.291 | Train PPL:   1.338\n","\t Val. Loss: 1.654 |  Val. PPL:   5.228\n","Epoch: 151 | Time: 0m 0s\n","\tTrain Loss: 0.245 | Train PPL:   1.277\n","\t Val. Loss: 1.675 |  Val. PPL:   5.341\n","Epoch: 152 | Time: 0m 1s\n","\tTrain Loss: 0.337 | Train PPL:   1.401\n","\t Val. Loss: 1.655 |  Val. PPL:   5.232\n","Epoch: 153 | Time: 0m 0s\n","\tTrain Loss: 0.301 | Train PPL:   1.351\n","\t Val. Loss: 1.775 |  Val. PPL:   5.899\n","Epoch: 154 | Time: 0m 0s\n","\tTrain Loss: 0.313 | Train PPL:   1.367\n","\t Val. Loss: 1.729 |  Val. PPL:   5.636\n","Epoch: 155 | Time: 0m 0s\n","\tTrain Loss: 0.274 | Train PPL:   1.315\n","\t Val. Loss: 1.800 |  Val. PPL:   6.048\n","Epoch: 156 | Time: 0m 0s\n","\tTrain Loss: 0.230 | Train PPL:   1.259\n","\t Val. Loss: 1.699 |  Val. PPL:   5.466\n","Epoch: 157 | Time: 0m 0s\n","\tTrain Loss: 0.276 | Train PPL:   1.317\n","\t Val. Loss: 1.690 |  Val. PPL:   5.422\n","Epoch: 158 | Time: 0m 0s\n","\tTrain Loss: 0.250 | Train PPL:   1.284\n","\t Val. Loss: 1.707 |  Val. PPL:   5.510\n","Epoch: 159 | Time: 0m 0s\n","\tTrain Loss: 0.317 | Train PPL:   1.373\n","\t Val. Loss: 1.776 |  Val. PPL:   5.907\n","Epoch: 160 | Time: 0m 0s\n","\tTrain Loss: 0.253 | Train PPL:   1.288\n","\t Val. Loss: 1.808 |  Val. PPL:   6.098\n","Epoch: 161 | Time: 0m 0s\n","\tTrain Loss: 0.274 | Train PPL:   1.315\n","\t Val. Loss: 1.729 |  Val. PPL:   5.634\n","Epoch: 162 | Time: 0m 0s\n","\tTrain Loss: 0.287 | Train PPL:   1.333\n","\t Val. Loss: 1.837 |  Val. PPL:   6.275\n","Epoch: 163 | Time: 0m 0s\n","\tTrain Loss: 0.308 | Train PPL:   1.360\n","\t Val. Loss: 1.742 |  Val. PPL:   5.710\n","Epoch: 164 | Time: 0m 0s\n","\tTrain Loss: 0.285 | Train PPL:   1.329\n","\t Val. Loss: 1.804 |  Val. PPL:   6.074\n","Epoch: 165 | Time: 0m 0s\n","\tTrain Loss: 0.241 | Train PPL:   1.272\n","\t Val. Loss: 1.774 |  Val. PPL:   5.895\n","Epoch: 166 | Time: 0m 0s\n","\tTrain Loss: 0.258 | Train PPL:   1.294\n","\t Val. Loss: 1.845 |  Val. PPL:   6.326\n","Epoch: 167 | Time: 0m 0s\n","\tTrain Loss: 0.216 | Train PPL:   1.242\n","\t Val. Loss: 1.854 |  Val. PPL:   6.385\n","Epoch: 168 | Time: 0m 0s\n","\tTrain Loss: 0.238 | Train PPL:   1.268\n","\t Val. Loss: 1.774 |  Val. PPL:   5.893\n","Epoch: 169 | Time: 0m 0s\n","\tTrain Loss: 0.194 | Train PPL:   1.214\n","\t Val. Loss: 1.829 |  Val. PPL:   6.228\n","Epoch: 170 | Time: 0m 0s\n","\tTrain Loss: 0.284 | Train PPL:   1.329\n","\t Val. Loss: 1.824 |  Val. PPL:   6.199\n","Epoch: 171 | Time: 0m 0s\n","\tTrain Loss: 0.223 | Train PPL:   1.250\n","\t Val. Loss: 1.875 |  Val. PPL:   6.523\n","Epoch: 172 | Time: 0m 0s\n","\tTrain Loss: 0.259 | Train PPL:   1.296\n","\t Val. Loss: 1.871 |  Val. PPL:   6.496\n","Epoch: 173 | Time: 0m 0s\n","\tTrain Loss: 0.267 | Train PPL:   1.307\n","\t Val. Loss: 1.841 |  Val. PPL:   6.303\n","Epoch: 174 | Time: 0m 0s\n","\tTrain Loss: 0.248 | Train PPL:   1.282\n","\t Val. Loss: 1.825 |  Val. PPL:   6.205\n","Epoch: 175 | Time: 0m 0s\n","\tTrain Loss: 0.250 | Train PPL:   1.283\n","\t Val. Loss: 1.912 |  Val. PPL:   6.764\n","Epoch: 176 | Time: 0m 1s\n","\tTrain Loss: 0.224 | Train PPL:   1.251\n","\t Val. Loss: 1.871 |  Val. PPL:   6.496\n","Epoch: 177 | Time: 0m 0s\n","\tTrain Loss: 0.199 | Train PPL:   1.220\n","\t Val. Loss: 1.871 |  Val. PPL:   6.492\n","Epoch: 178 | Time: 0m 0s\n","\tTrain Loss: 0.207 | Train PPL:   1.229\n","\t Val. Loss: 1.857 |  Val. PPL:   6.404\n","Epoch: 179 | Time: 0m 0s\n","\tTrain Loss: 0.214 | Train PPL:   1.238\n","\t Val. Loss: 1.867 |  Val. PPL:   6.470\n","Epoch: 180 | Time: 0m 0s\n","\tTrain Loss: 0.206 | Train PPL:   1.228\n","\t Val. Loss: 1.783 |  Val. PPL:   5.950\n","Epoch: 181 | Time: 0m 0s\n","\tTrain Loss: 0.217 | Train PPL:   1.242\n","\t Val. Loss: 1.789 |  Val. PPL:   5.984\n","Epoch: 182 | Time: 0m 0s\n","\tTrain Loss: 0.197 | Train PPL:   1.217\n","\t Val. Loss: 1.884 |  Val. PPL:   6.580\n","Epoch: 183 | Time: 0m 0s\n","\tTrain Loss: 0.179 | Train PPL:   1.196\n","\t Val. Loss: 1.866 |  Val. PPL:   6.462\n","Epoch: 184 | Time: 0m 0s\n","\tTrain Loss: 0.196 | Train PPL:   1.216\n","\t Val. Loss: 1.900 |  Val. PPL:   6.686\n","Epoch: 185 | Time: 0m 0s\n","\tTrain Loss: 0.199 | Train PPL:   1.220\n","\t Val. Loss: 1.895 |  Val. PPL:   6.653\n","Epoch: 186 | Time: 0m 0s\n","\tTrain Loss: 0.227 | Train PPL:   1.255\n","\t Val. Loss: 1.898 |  Val. PPL:   6.671\n","Epoch: 187 | Time: 0m 0s\n","\tTrain Loss: 0.251 | Train PPL:   1.285\n","\t Val. Loss: 1.790 |  Val. PPL:   5.987\n","Epoch: 188 | Time: 0m 0s\n","\tTrain Loss: 0.260 | Train PPL:   1.297\n","\t Val. Loss: 1.815 |  Val. PPL:   6.139\n","Epoch: 189 | Time: 0m 0s\n","\tTrain Loss: 0.218 | Train PPL:   1.243\n","\t Val. Loss: 1.858 |  Val. PPL:   6.410\n","Epoch: 190 | Time: 0m 0s\n","\tTrain Loss: 0.203 | Train PPL:   1.225\n","\t Val. Loss: 1.851 |  Val. PPL:   6.369\n","Epoch: 191 | Time: 0m 0s\n","\tTrain Loss: 0.257 | Train PPL:   1.292\n","\t Val. Loss: 1.829 |  Val. PPL:   6.227\n","Epoch: 192 | Time: 0m 0s\n","\tTrain Loss: 0.229 | Train PPL:   1.258\n","\t Val. Loss: 1.819 |  Val. PPL:   6.168\n","Epoch: 193 | Time: 0m 0s\n","\tTrain Loss: 0.198 | Train PPL:   1.219\n","\t Val. Loss: 1.854 |  Val. PPL:   6.386\n","Epoch: 194 | Time: 0m 0s\n","\tTrain Loss: 0.182 | Train PPL:   1.199\n","\t Val. Loss: 1.869 |  Val. PPL:   6.481\n","Epoch: 195 | Time: 0m 1s\n","\tTrain Loss: 0.344 | Train PPL:   1.410\n","\t Val. Loss: 1.945 |  Val. PPL:   6.994\n","Epoch: 196 | Time: 0m 0s\n","\tTrain Loss: 0.158 | Train PPL:   1.172\n","\t Val. Loss: 1.833 |  Val. PPL:   6.254\n","Epoch: 197 | Time: 0m 1s\n","\tTrain Loss: 0.187 | Train PPL:   1.206\n","\t Val. Loss: 1.826 |  Val. PPL:   6.211\n","Epoch: 198 | Time: 0m 0s\n","\tTrain Loss: 0.184 | Train PPL:   1.202\n","\t Val. Loss: 1.936 |  Val. PPL:   6.929\n","Epoch: 199 | Time: 0m 0s\n","\tTrain Loss: 0.218 | Train PPL:   1.243\n","\t Val. Loss: 1.966 |  Val. PPL:   7.140\n","Epoch: 200 | Time: 0m 0s\n","\tTrain Loss: 0.182 | Train PPL:   1.199\n","\t Val. Loss: 1.982 |  Val. PPL:   7.259\n"]}]},{"cell_type":"code","source":["def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n","\n","    model.eval()\n","\n","    if isinstance(sentence, str):\n","        nlp = Russian()\n","        tokens = [token.text.lower() for token in nlp(sentence)]\n","    else:\n","        tokens = [token.lower() for token in sentence]\n","\n","    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n","\n","    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n","\n","    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n","\n","    src_len = torch.LongTensor([len(src_indexes)])\n","\n","    with torch.no_grad():\n","        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\n","\n","    mask = model.create_mask(src_tensor)\n","\n","    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n","\n","    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n","\n","    for i in range(max_len):\n","\n","        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n","\n","        with torch.no_grad():\n","            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n","\n","        attentions[i] = attention\n","\n","        pred_token = output.argmax(1).item()\n","\n","        trg_indexes.append(pred_token)\n","\n","        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n","            break\n","\n","    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n","\n","    return trg_tokens[1:-1], attentions[:len(trg_tokens)-1]"],"metadata":{"id":"cLUm5OatZVNw","executionInfo":{"status":"ok","timestamp":1719661622595,"user_tz":-180,"elapsed":265,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}}},"execution_count":364,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('tut4-model.pt'))\n","\n","test_loss = evaluate(model, test_iterator, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jjb5CaYITgiT","executionInfo":{"status":"ok","timestamp":1719661922606,"user_tz":-180,"elapsed":403,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"21c7aac1-4aab-450f-fd65-e71375796d30"},"execution_count":366,"outputs":[{"output_type":"stream","name":"stdout","text":["| Test Loss: 3.594 | Test PPL:  36.362 |\n"]}]},{"cell_type":"code","source":["example_idx = 2\n","\n","src = vars(train_data.examples[example_idx])['src']\n","trg = vars(train_data.examples[example_idx])['trg']\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')"],"metadata":{"id":"OW4si6moUCLJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719661974306,"user_tz":-180,"elapsed":303,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"5f82ceb8-4034-4527-a265-25a533a32c0e"},"execution_count":379,"outputs":[{"output_type":"stream","name":"stdout","text":["src = ['давайте', 'что', '-', 'нибудь', 'попробуем', '!']\n","trg = ['let', \"'s\", 'try', 'something', '.']\n"]}]},{"cell_type":"code","source":["translation, attention = translate_sentence(src, SRC, TRG, model, device)\n","\n","print(f'predicted trg = {translation}')"],"metadata":{"id":"pFArDl7dUDis","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719661974733,"user_tz":-180,"elapsed":1,"user":{"displayName":"Станислав Нестеров","userId":"13882497640647044506"}},"outputId":"122cf1fa-771b-4295-c06b-1c72bb5b3fb2"},"execution_count":380,"outputs":[{"output_type":"stream","name":"stdout","text":["predicted trg = ['let', \"'s\", '<unk>', 'something', '.']\n"]}]},{"cell_type":"markdown","source":[" Для более качественной и непереобученной модели, как и говорилось в лекции, требуются большие мощности, поэтому сделал тестовый вариант архитектуры и взял небольшую выборку, чтобы показать весь механизм работы.\n","\n"],"metadata":{"id":"6NpHPXYK1F5N"}},{"cell_type":"code","source":[],"metadata":{"id":"sop81YS5rumV"},"execution_count":null,"outputs":[]}]}